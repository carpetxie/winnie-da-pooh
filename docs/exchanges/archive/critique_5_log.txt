Critique written to `docs/exchanges/critique_latest.md`. Here's a summary:

## Iteration 5 Critique — Key Points

**Overall**: The paper has improved substantially. All iteration 4 changes were productive. No dead-end suggestions from last round.

**Scores**: Narrative Clarity and Blog Publishability both +1 (now 7/10 each). Methodological Rigor holds at 8/10.

**The One Big Thing**: The permutation test (p<0.001) pools raw CRPS and MAE values across series with ~100,000x scale differences. This conflates scale mixing with calibration heterogeneity. A 3-line fix (permute per-event CRPS/MAE ratios instead) makes the test scale-free and bulletproof.

**Key findings from code review**:
1. **Permutation test scale-mixing** — not a bug, but tests a composite hypothesis. MWU tests are cleaner and should lead the heterogeneity paragraph.
2. **Experiment 8 stationarity alignment** — potential index mismatch after independent differencing; Granger result already properly hedged.
3. **Hardcoded realized values** in horse_race.py — standard but worth documenting.

**Should Fix** (4 items): Swap MWU/permutation emphasis, strengthen the point-vs-distribution decoupling novelty claim, add temporal robustness to abstract, tighten abstract length.

**New experiments**: Scale-free permutation test (~5 lines), block bootstrap for CPI serial correlation (~15 lines), Anderson-Darling test for PIT (~2 lines).

**Verdict**: **MINOR REVISIONS** — publishable after polish.
